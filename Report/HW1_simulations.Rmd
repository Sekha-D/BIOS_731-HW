---
title: "Homework 1"
author: "Sekha Daluwatumulle"
output: 
  pdf_document:
    extra_dependencies: ["booktabs", "float"]
    keep_tex: false
    highlight: haddock
urlcolor: blue    
---

```{r, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(tidy = FALSE)
library(ggplot2)
```

## Context

This assignment reinforces ideas in Module 1: Reproducible computing in R. We focus specifically on implementing a large scale simulation study, but the assignment will also include components involving bootstrap and parallelization, Git/GitHub, and project organization.


## Due date and submission

Please submit (via Canvas) a PDF knitted from .Rmd. Your PDF should include the web address of the GitHub repo containing your work for this assignment; git commits after the due date will cause the assignment to be considered late.  

R Markdown documents included as part of your solutions must not install packages, and should only load the packages necessary for your submission to knit.



## Points

```{r, echo = FALSE}
tibble(
  Problem = c("Problem 0", "Problem 1.1", "Problem 1.2", "Problem 1.3", "Problem 1.4", "Problem 1.5"),
  Points = c(20, 10, 5, 20, 30, 15)
) %>%
  knitr::kable()
```


## Problem 0 

This “problem” focuses on structure of your submission, especially the use git and GitHub for reproducibility, R Projects to organize your work, R Markdown to write reproducible reports, relative paths to load data from local files, and reasonable naming structures for your files.

To that end:

* create a public GitHub repo + local R Project; I suggest naming this repo / directory bios731_hw1_YourLastName (e.g. bios731_hw1_wrobel for Julia)
* Submit your whole project folder to GitHub 
* Submit a PDF knitted from Rmd to Canvas. Your solutions to the problem here should be implemented in your .Rmd file, and your git commit history should reflect the process you used to solve these Problems.

\textcolor{blue} {The link to my repository:}

https://github.com/Sekha-D/BIOS_731-HW.git

## Problem 1

Simulation study: our goal in this homework will be to plan a well-organized simulation study for multiple linear regression and bootstrapped confidence intervals. 


Below is a multiple linear regression model, where we are interested in primarily treatment effect.


$$Y_i = \beta_0 + \beta_{treatment}X_{i1} + \mathbf{Z_i}^T\boldsymbol{\gamma} + \epsilon_i$$


Notation is defined below: 

* $Y_i$: continuous outcome
* $X_{i1}$: treatment group indicator; $X_{i1}=1$ for treated 
* $\mathbf{Z_i}$: vector of potential confounders
* $\beta_{treatment}$: average treatment effect, adjusting for $\mathbf{Z_i}$
* $\boldsymbol{\gamma}$: vector of regression coefficient values for confounders 
* $\epsilon_i$: errors, we will vary how these are defined


In our simulation, we want to 

* Estimate $\beta_{treatment}$ and $se(\hat{\beta}_{treatment})$
  * Evaluate $\beta_{treatment}$ through bias and coverage
  * We will use 3 methods to compute $se(\hat{\beta}_{treatment})$ and coverage:
    1. Wald confidence intervals (the standard approach)
    2. Nonparametric bootstrap percentile intervals
    3. Nonparametric bootstrap $t$ intervals
  * Evaluate computation times for each method to compute a confidence interval

* Evaluate these properties at:
  - Sample size $n \in \{10, 50, 500\}$
  - True values $\beta_{treatment} \in \{0, 0.5, 2\}$
  - True $\epsilon_i$ normally distributed with $\epsilon_i \sim N(0, 2)$
  - True $\epsilon_i$ coming from a right skewed distribution
    - **Hint**: try $\epsilon_i \sim logNormal(0, \log (2))$

* Assume that there are no confounders ($\boldsymbol{\gamma} = 0$)
* Use a full factorial design



### Problem 1.1 ADEMP Structure 

Answer the following questions: 

* How many simulation scenarios will you be running? 

\textcolor{blue} {I would be running 18 different simulation scenarios.}

* What are the estimand(s)

\textcolor{blue} {$\beta_{treatment}$ , standard error of $\hat\beta_{treatment}$}

* What method(s) are being evaluated/compared?

\textcolor{blue} {Estimation using the standard regression calculations, also known as the wald method (denoted as Walds throughout this report).}

\textcolor{blue} {Estimation using the bootstrap percentile interval method (denoted as Boot P throughout this report).}

\textcolor{blue} {Estimation using the bootstrap t interval method (denoted as Boot t throughout this report).}

\textcolor{blue} {Note: For both bootstrap method s,  I used the residual method}

* What are the performance measure(s)?

\textcolor{blue} {Bias, coverage probabilities for the three methods, and also the computational times for the three methods.}

\textcolor{blue} {Note: Bias was only calculated using Wald's method. Only $se(\hat{\beta}_{treatment})$ and coverage were calculated using the three methods according according to problem 1. Not sure if we also need to calculate bias according to three methods.} 

### Problem 1.2 nSim 

Based on desired coverage of 95\% with Monte Carlo error of no more than 1\%, how many simulations ($n_{sim}$) should we perform for each simulation scenario?  Implement this number of simulations throughout your simulation study.

```{r, echo = FALSE}
nsim= 0.95*(1 - 0.95)/(0.01)^2

```

\textcolor{blue} {number of simulations=`r nsim`}


### Problem 1.3 Implementation 


We will execute this full simulation study. For full credit, make sure to implement the following:

* Well structured scripts and subfolders following guidance from `project_organization` lecture
* Use relative file paths to access intermediate scripts and data objects
* Use readable code practices
* Parallelize your simulation scenarios
* Save results from each simulation scenario in an intermediate `.Rda` or `.rds` dataset in a `data` subfolder 
  * Ignore these data files in your `.gitignore` file so when pushing and committing to GitHub they don't get pushed to remote 
* Make sure your folder contains a Readme explaining the workflow of your simulation study
  * should include how files are executed and in what order 
* Ensure reproducibility! I should be able to clone your GitHub repo, open your `.Rproj` file, and run your simulation study

### Problem 1.4 Results summary

Create a plot or table to summarize simulation results across scenarios and methods for each of the following. 

- Bias of $\hat{\beta}$
- Coverage of $\hat{\beta}$
- Distribution of $se(\hat{\beta})$
- Computation time across methods

If creating a plot, I encourage faceting. Include informative captions for each plot and/or table.

```{r, echo = FALSE}
load(file = here::here("results", "summary_table.RDA"))

# sd_wald<-data.frame(matrix(nrow=nsim,ncol=no_scenario))
# sd_boot<-data.frame(matrix(nrow=nsim,ncol=no_scenario))
# for (i in 1:no_scenario){
#     filename = paste0("scenario_", paste(param_grid[i,],collapse = "_"), ".RDA")
#     load(file = here::here("results", filename))
#     sd_wald[,i]=y=results[,2]
#     colnames(sd_wald)[i]<-paste(param_grid[i,],collapse = "_")
# 
#     sd_boot[,i]=y=results[,8]
#     colnames(sd_boot)[i]<-paste(param_grid[i,],collapse = "_")
# 
# }


```

\begin{table}[H]
\centering
\caption {A summary of the obtained results. Bias is calculated under the Wald's method. Coverage probabilities were calculated under the three methods given in problem 1.1. Time column indicates the elapsed time in seconds to conduct all the 475 simulations. Results are organised according to the different data generation procedures. Here we generated data from two distributions N(0,2) and lognormal (0,log(2)), with $\beta_{treatment}$=\{0,0.5, 2\}, and n=\{10,50, 500\}
\label{table1}} 
\begin{tabular}{ccc|ccccccc}
\toprule
&&& $Bias$ &   & $Coverage$& & & $Time$ &\\ 
&&&  & $Walds$ & $Boot\,p$ &$Boot\, t$ &$Walds$ & $Boot\,p$ &$Boot\, t$ \\
\midrule
$N(0,2)$& $\beta=0$  &$n=10$ &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==0),5],4)` &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==0),6] ,4)`  &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==0),7],4)` & `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==0),8],4)` &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==0),9],4)` & `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==0),10] ,4)`&  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==0),11],4)`\\
&& $n=50$ &  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==0),5],4)` &  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==0),6] ,4)`  &  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==0),7],4)` & `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==0),8],4)` &  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==0),9],4)` & `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==0),10] ,4)`&  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==0),11],4)`\\
&&$n=500$&  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==0),5],4)` &  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==0),6] ,4)`  &  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==0),7],4)` & `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==0),8],4)` &  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==0),9],4)` & `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==0),10] ,4)`&  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==0),11],4)`\\

& $\beta=0.5$   &$n=10$ &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),5],4)` &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),6] ,4)`  &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),7],4)` & `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),8],4)` &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),9],4)` & `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),10] ,4)`&  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),11],4)`\\
&& $n=50$& `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),5],4)` &  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),6] ,4)`  &  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),7],4)` & `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),8],4)` &  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),9],4)` & `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),10] ,4)`&  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),11],4)`\\
&&$n=500$&  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),5],4)` &  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),6] ,4)`  &  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),7],4)` & `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),8],4)` &  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),9],4)` & `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),10] ,4)`&  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==0.5),11],4)`\\

& $\beta=2$   &$n=10$ &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==2),5],4)` &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==2),6] ,4)`  &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==2),7],4)` & `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==2),8],4)` &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==2),9],4)` & `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==2),10] ,4)`&  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==2 &summary_table$beta_true==2),11],4)`\\
&& $n=50$& `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==2),5],4)` &  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==2),6] ,4)`  &  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==2),7],4)` & `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==2),8],4)` &  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==2),9],4)` & `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==2),10] ,4)`&  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==2 &summary_table$beta_true==2),11],4)`\\
&&$n=500$&  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==2),5],4)` &  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==2),6] ,4)`  &  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==2),7],4)` & `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==2),8],4)` &  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==2),9],4)` & `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==2),10] ,4)`&  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==2 &summary_table$beta_true==2),11],4)`\\

$logN(0,log(2))$& $\beta=0$  &$n=10$ &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),5],4)` &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),6] ,4)`  &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),7],4)` & `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),8],4)` &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),9],4)` & `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),10] ,4)`&  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),11],4)`\\
&& $n=50$ &  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),5],4)` &  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),6] ,4)`  &  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),7],4)` & `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),8],4)` &  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),9],4)` & `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),10] ,4)`&  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),11],4)`\\
&&$n=500$&  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),5],4)` &  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),6] ,4)`  &  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),7],4)` & `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),8],4)` &  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),9],4)` & `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),10] ,4)`&  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0),11],4)`\\

& $\beta=0.5$   &$n=10$ &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),5],4)` &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),6] ,4)`  &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),7],4)` & `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),8],4)` &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),9],4)` & `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),10] ,4)`&  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),11],4)`\\
&& $n=50$& `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),5],4)` &  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),6] ,4)`  &  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),7],4)` & `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),8],4)` &  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),9],4)` & `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),10] ,4)`&  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),11],4)`\\
&&$n=500$&  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),5],4)` &  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),6] ,4)`  &  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),7],4)` & `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),8],4)` &  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),9],4)` & `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),10] ,4)`&  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==0.5),11],4)`\\

& $\beta=2$   &$n=10$ &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),5],4)` &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),6] ,4)`  &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),7],4)` & `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),8],4)` &  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),9],4)` & `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),10] ,4)`&  `r round(summary_table[which(summary_table$n==10 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),11],4)`\\
&& $n=50$& `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),5],4)` &  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),6] ,4)`  &  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),7],4)` & `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),8],4)` &  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),9],4)` & `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),10] ,4)`&  `r round(summary_table[which(summary_table$n==50 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),11],4)`\\
&&$n=500$&  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),5],4)` &  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),6] ,4)`  &  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),7],4)` & `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),8],4)` &  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),9],4)` & `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),10] ,4)`&  `r round(summary_table[which(summary_table$n==500 & summary_table$sigma2_true==log(2) &summary_table$beta_true==2),11],4)`\\
\bottomrule
\end{tabular}
\end{table}

```{r, echo = FALSE, fig.height=20, fig.width=15, fig.cap="Distribution of standard deviation of estimated using walds method"}
B=500
nt=500
alpha=0.05
nsim=0.95*(1 - 0.95)/(0.01)^2

n = c(10, 50, 500)
beta_true = c(0, 0.5, 2)
sigma2_true = c(2, log(2))

param_grid = expand.grid(n = n,
                     beta_true = beta_true,
                     sigma2_true = sigma2_true)

no_scenario=nrow(param_grid)

param_grid2 = expand.grid(n = n,
                     beta_true = beta_true,
                     sigma2_true = c("N(0,2)","lognormal(N,log(2))"))

sd_wald<-data.frame(matrix(nrow=nsim,ncol=no_scenario))
sd_boot<-data.frame(matrix(nrow=nsim,ncol=no_scenario))
for (i in 1:no_scenario){
    filename = paste0("scenario_", paste(param_grid[i,],collapse = "_"), ".RDA")
    load(file = here::here("results", filename))
    sd_wald[,i]=y=results[,2]
    colnames(sd_wald)[i]<-paste(param_grid2[i,1],param_grid2[i,2],param_grid2[i,3],sep="_")

    sd_boot[,i]=y=results[,8]
    colnames(sd_boot)[i]<-paste(param_grid2[i,1],param_grid2[i,2],param_grid2[i,3],sep="_")

}

df_long1 <- sd_wald %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Value")

ggplot(df_long1, aes(x = Value)) +
  geom_histogram(bins = 30, fill = "blue", color = "black", alpha = 0.7) +
  facet_wrap(~ Variable, scales = "free",ncol=3) +
  theme_minimal() +theme(strip.text = element_text(size = 20))+
  labs(title = bquote("Plot of SD when n_" ~ beta ~ "_ "
    ~ sigma^2), x = "Standard deviation (SD)", y = "Frequency")
```

```{r, echo = FALSE, fig.height=20, fig.width=15, fig.cap="Distribution of standard deviation of estimated using bootstrap method"}
df_long2 <- sd_boot %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Value")

ggplot(df_long2, aes(x = Value)) +
  geom_histogram(bins = 30, fill = "blue", color = "black", alpha = 0.7) +
  facet_wrap(~ Variable, scales = "free",ncol=3) +
  theme_minimal() +theme(strip.text = element_text(size = 20))+
  labs(title = bquote("Plot of SD when n_" ~ beta ~ "_ "
    ~ sigma^2), x = "Standard deviation (SD)", y = "Frequency")



```

### Problem 1.5 Discussion

Interpret the results summarized in Problem 1.4. First, write a **paragraph** summarizing the main findings of your simulation study. Then, answer the specific questions below.

\textcolor{blue} {The bias using the standard regression approach (Walds) decrease as sample size increase. The bias values do not seem to change across $\beta_{treatment}$. Coverage probabilities for Walds method are all closer to 95\%. However, it is slightly different (around 96\%) under the lognormal distribution. Contrary to the belief that when n is large coverage probabilities are high, we can see that coverage for Wald's when n=500 is around 93\%. The coverage of both the bootstrap methods is low when n is small (n=10). It is around 85\% and 90\% under the normal and lognormal assumptions respectively. As sample size increase, both the boostrap methods perform well, with coverage probabilities close to 95\%.   Under the skewed data and when n=500, bootstrap percentile interval's coverage probability is the closest to 95\%. This indicates that bootstrap method works better when data are skewed (data generated from lognormal) The coverage probabilities don't seem to change across $\beta_{treatment}$ values either.}


\textcolor{blue} {By comparing Figure 1 and 2, we can see that the distributions of standard deviation of $\hat\beta_{treatment}$ for the two methods (Wald and bootstrap) are quite similar with slight changes. Under the lognormal data assumption, the range of $se(\hat\beta_{treatment})$ is slightly larger in Wald's method compared to bootstrap methods. When the data are generated using a normal distribution, the distribution of $se(\hat\beta_{treatment})$s also look like a normal distribution visually, and when the data are generated using the lognormal distribution, the distribution of $se(\hat\beta_{treatment})$ seems to be skewed as well. When the sample size increase, the range of $se(\hat\beta_{treatment})$ decrease quite considerably, indicating that when n is high there is low variance in the estimates. The distribution of $se(\hat\beta_{treatment})$ do not seem to vary across different $\beta_{treatment}$ }

- How do the different methods for constructing confidence intervals compare in terms of computation time?

\textcolor{blue} {The computaional times calculated in Table 2 is the total elapsed time in seconds took to complete all the `r nsim` simulations. We can see that Wald's method took the least number of seconds. Therefore, Wald's method is the fastest, next bootstrap percentile and the slowest is the boostrap t interval method.  }

- Which method(s) for constructing confidence intervals provide the best coverage when $\epsilon_i \sim N(0, 2)$?

\textcolor{blue} {Walds method}

- Which method(s) for constructing confidence intervals provide the best coverage when $\epsilon_i \sim logNormal(0, \log (2))$?

\textcolor{blue} {Bootstrap percentile when sample size is large enough, if the sample size is like 10 Wald would be better}
